{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: [MoNuSeg](https://monuseg.grand-challenge.org/Data/)\n",
    "\n",
    "Model Architecture: [UNET](https://pypi.org/project/segmentation-models-pytorch/#architectures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm as loadingbar\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets.MoNuSeg.FileReader import files, get_image, get_mask\n",
    "from Datasets.MoNuSeg.FileViewer import show_image, show_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and Dataloader\n",
    "\n",
    "class MoNuSegDataset(Dataset):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.files = files\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index) -> tuple:\n",
    "        filename = self.files[index]\n",
    "        return get_image(filename), get_mask(filename)\n",
    "\n",
    "class MoNuSegDataLoader(DataLoader):\n",
    "\n",
    "    def __init__(self, batch_size=5):\n",
    "        super().__init__(MoNuSegDataset(), shuffle=True, batch_size=5, drop_last=True)\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "dataloader = MoNuSegDataLoader()\n",
    "\n",
    "# crops an entire batch for faster processing\n",
    "image_size = 1000\n",
    "crop_size = 512\n",
    "ignored_edge_size = 4\n",
    "def crop_batch(images, masks):\n",
    "    x, y = torch.randint(ignored_edge_size, image_size - crop_size - ignored_edge_size, size=(1,2)).squeeze().tolist()\n",
    "    assert (len(images.shape) == len(masks.shape))\n",
    "    if len(images.shape) == 4:\n",
    "        images = images[:, :, y:y+crop_size, x:x+crop_size]\n",
    "        masks = masks[:, :, y:y+crop_size, x:x+crop_size]\n",
    "    elif len(images.shape) == 3:\n",
    "        images = images[:, y:y+crop_size, x:x+crop_size]\n",
    "        masks = masks[:, y:y+crop_size, x:x+crop_size]\n",
    "    return images, masks\n",
    "\n",
    "rotations = [0, 90, 180, 270]\n",
    "def rotate_batch(images, masks):\n",
    "    rotation = int(np.random.choice(rotations))\n",
    "    images = transforms.functional.rotate(images, rotation)\n",
    "    masks = transforms.functional.rotate(masks, rotation)\n",
    "    return images, masks\n",
    "\n",
    "def preprocess_batch(images, masks):\n",
    "    return rotate_batch(*crop_batch(images, masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example use\n",
    "for batch_num, (images, masks) in enumerate(dataloader):\n",
    "    images, masks = crop_batch(images, masks)\n",
    "    images, masks = rotate_batch(images, masks)\n",
    "    show_image(images[0])\n",
    "    show_mask(masks[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils for batch and individual image shaping\n",
    "def ensure_batch(t):\n",
    "    if len(t.shape) == 3:\n",
    "        return t.unsqueeze(0)\n",
    "    else:\n",
    "        return t\n",
    "def ensure_individual_image(t, batch_to_single_index = 0):\n",
    "    if len(t.shape) == 3:\n",
    "        return t\n",
    "    else:\n",
    "        if t.shape[0] > 1:\n",
    "            return t[batch_to_single_index]\n",
    "        else:\n",
    "            return t.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    torch.save(model, f\"pretrained-models/{model_name}.model\")\n",
    "\n",
    "def load_model(model_name):\n",
    "    with open(f\"pretrained-models/{model_name}.model\", 'r') as f:\n",
    "        return torch.load(f)\n",
    "\n",
    "def train_model(model, epochs=3, batch_size=5, loss=None, optimizer=None):\n",
    "    # process args\n",
    "    if loss is None: loss = smp.utils.losses.DiceLoss()\n",
    "    if optimizer is None: optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    # initialize dataloader\n",
    "    dataloader = MoNuSegDataLoader(batch_size)\n",
    "    # train model\n",
    "    for epoch in loadingbar(range(epochs)):\n",
    "        for batch_num, (images, masks) in enumerate(dataloader):\n",
    "            images, masks = preprocess_batch(images, masks)\n",
    "            optimizer.zero_grad()\n",
    "            yhat_batch = model.forward(images)\n",
    "            loss_batch = loss(yhat_batch, masks)\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "def test_model(model, image, mask=None, show_things=False):\n",
    "    if show_things: show_image(ensure_individual_image(image))\n",
    "    if show_things and mask is not None: show_mask(ensure_individual_image(mask))\n",
    "    predicted_mask = model.forward(ensure_batch(image))\n",
    "    predicted_mask = ensure_individual_image(predicted_mask)\n",
    "    if show_things: show_mask(predicted_mask)\n",
    "    return predicted_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intiailize model\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"vgg16\",\n",
    "    activation=\"sigmoid\"\n",
    ")\n",
    "\n",
    "# training details\n",
    "epochs = 40\n",
    "batch_size = 5\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# initialize dataloader\n",
    "dataloader = MoNuSegDataLoader(batch_size)\n",
    "\n",
    "# epoch functions\n",
    "def do_epoch():\n",
    "    for batch_num, (images, masks) in enumerate(dataloader):\n",
    "        images, masks = preprocess_batch(images, masks)\n",
    "        optimizer.zero_grad()\n",
    "        yhat_batch = model.forward(images)\n",
    "        loss_batch = loss(yhat_batch, masks)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "def do_epochs(epochs):\n",
    "    for epoch_num in loadingbar(range(epochs), desc=\"Epoch Counter\", leave=True):\n",
    "        do_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    batch = MoNuSegDataset()[0]\n",
    "    batch = preprocess_batch(*batch)\n",
    "    show_image(batch[0])\n",
    "    show_mask(batch[1])\n",
    "    test_out = model.forward(batch[0].unsqueeze(0))\n",
    "    show_mask(test_out.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_epochs(5)\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_epochs(5)\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_epochs(5)\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "model_save_15_epochs = copy.deepcopy(model)\n",
    "do_epochs(5)\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_20_epochs = copy.deepcopy(model)\n",
    "do_epochs(5)\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_save_20_epochs\n",
    "torch.save(model.state_dict(), \"temp.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Model to Labelled Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cell crops\n",
    "files_eocell = [\"96.jpg\", \"138.jpg\", \"1584.jpg\", \"1755.jpg\"]\n",
    "files_neutro = [\"193.jpg\", \"461.jpg\", \"667.jpg\", \"816.jpg\"]\n",
    "files = [f\"pretrained-data/LabeledCellCrops/{f}\" for f in (\n",
    "    [f\"eosinophil/{e}\" for e in files_eocell] + \n",
    "    [f\"neutrophil/{n}\" for n in files_neutro]\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell crop padding and unpadded\n",
    "\n",
    "class CellCropPadder(object):\n",
    "    def __init__(self, size=256, value=0, placement=50) -> None:\n",
    "        self.size = size\n",
    "        self.value = value\n",
    "        self.placement = placement\n",
    "    def __call__(self, image) -> torch.Tensor:\n",
    "        image = ensure_individual_image(image)\n",
    "        padded_image = torch.ones(size=(image.shape[0], self.size, self.size)) * self.value\n",
    "        padded_image[:, self.placement:self.placement+image.shape[1], self.placement:self.placement+image.shape[2]] += image\n",
    "        return padded_image\n",
    "\n",
    "class CellCropUnpadder(object):\n",
    "    def __init__(self, padded_image):\n",
    "        self.image = ensure_individual_image(padded_image)\n",
    "        padded_img_width = self.image.shape[2]\n",
    "        padded_img_height = self.image.shape[1]\n",
    "        # initialize padding\n",
    "        self.left_pad = 0\n",
    "        self.right_pad = 0\n",
    "        self.top_pad = 0\n",
    "        self.bottom_pad = 0\n",
    "        # left/right pad deals with columns\n",
    "        while self.col_is_padding(self.left_pad): self.left_pad += 1\n",
    "        while self.col_is_padding(padded_img_width - 1 - self.right_pad): self.right_pad += 1\n",
    "        # top/bottom pad deals with rows:\n",
    "        while self.row_is_padding(self.top_pad): self.top_pad += 1\n",
    "        while self.row_is_padding(padded_img_height - 1 - self.bottom_pad): self.bottom_pad += 1\n",
    "    def __call__(self, image):\n",
    "        padded_image_width = image.shape[2]\n",
    "        padded_image_height = image.shape[1]\n",
    "        unpadded_image_width = padded_image_width - (self.left_pad + self.right_pad)\n",
    "        unpadded_image_height = padded_image_height - (self.top_pad + self.bottom_pad)\n",
    "        print(unpadded_image_width, unpadded_image_height)\n",
    "        unpadded_image = image[\n",
    "            :,\n",
    "            self.top_pad : self.top_pad + unpadded_image_height,\n",
    "            self.left_pad : self.left_pad + unpadded_image_width\n",
    "        ]\n",
    "        return unpadded_image\n",
    "    def row_is_padding(self, row_num): return len(torch.unique(self.image[:,row_num,:])) == 1\n",
    "    def col_is_padding(self, col_num): return len(torch.unique(self.image[:,:,col_num])) == 1\n",
    "    def get_pads(self): return self.left_pad, self.right_pad, self.top_pad, self.bottom_pad\n",
    "\n",
    "if False: # test these functions\n",
    "    unpadded_img = torch.Tensor([[[[1, 2], [3, 4], [5, 6]]]])\n",
    "    print(unpadded_img.shape)\n",
    "    print(unpadded_img)\n",
    "    padder = CellCropPadder(6, placement=1)\n",
    "    padded_img = padder(unpadded_img)\n",
    "    print(padded_img)\n",
    "    unpadder = CellCropUnpadder(padded_img)\n",
    "    padded_img_with_noise = padded_img.clone() + 1\n",
    "    print(unpadder.get_pads())\n",
    "    print(padded_img_with_noise)\n",
    "    unpadded_img = unpadder(padded_img_with_noise)\n",
    "    print(unpadded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process cell crop\n",
    "def get_cell_crop(cell_crop_filename):\n",
    "    return pil_to_tensor(Image.open(cell_crop_filename))\n",
    "def test_model_with_cell_crop(model, cell_crop_filename, threshold=0.5):\n",
    "    img = get_cell_crop(cell_crop_filename)\n",
    "    padder = CellCropPadder()\n",
    "    padded_img = padder(img)\n",
    "    prediction = test_model(model, padded_img)\n",
    "    unpadder = CellCropUnpadder(padded_img)\n",
    "    unpadded_prediction = unpadder(prediction)\n",
    "    final_prediction = (unpadded_prediction > threshold).to(unpadded_prediction.dtype)\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    print(f)\n",
    "    p = test_model_with_cell_crop(model, f)\n",
    "    show_image(p)\n",
    "    torchvision.utils.save_image(get_cell_crop(f), f.replace(\"eosinophil\",\"test-mask\").replace(\"neutrophil\",\"test-mask\").replace(\".jpg\",f\"-{'e' if 'eosinophil' in f else 'n'}.jpg\"))\n",
    "    torchvision.utils.save_image(p, f.replace(\"eosinophil\",\"test-mask\").replace(\"neutrophil\",\"test-mask\").replace(\".jpg\",f\"-{'e' if 'eosinophil' in f else 'n'}-m.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c4e08240db93eafa38ccafdb5bdcb597020ef973f599efbc041a4c7bdcb6919"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
